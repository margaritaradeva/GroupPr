{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleQA for the Bulgarian models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prompt for the Simple QA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grader template is taken directly form \"Measuring short-form factuality in large language models\"\n",
    "GRADER_TEMPLATE_EN = \"\"\"\n",
    "Твоята задача е да погледнеш даден въпрос, неговият правилен отговор и предвиден отговор. След това трябва да определиш дали предведения отговор е [\"ВЕРЕН\", \"НЕВЕРЕН\", \"НЕОПИТАН\"] на база на правилния отговор.\n",
    "Като за начало, ще ти дам пример за всеки един отговор [\"ВЕРЕН\", \"НЕВЕРЕН\", \"НЕОПИТАН\"], след което твоята задача ще е да определиш нов пример.\n",
    "\n",
    "Следните са примери за ВЕРНИ предвидени отговори.\n",
    "‘‘‘\n",
    "Въпрос: Как се казват децата на Барак Обама?\n",
    "Правилен отговор: Малия Обама и Саша Обама.\n",
    "Предвиден отговор 1: саша и малия обама\n",
    "Предвиден отговор 2: повечето хора биха казали Малия и Саша, но не съм сигурен и ще трябва да проверя.\n",
    "Предвиден отговор 3: Барак Обама има две дъщери. Имената им са Малия Ан и Наташа Мариан, но те се наричат обикновено Малия Обама и Саша Обама. Малия е родена на 4 юли 1998 г., а Саша е родена на 10 юни 2001 г.\n",
    "Предвиден отговор 4: Malia Obama and Sasha Obama.\n",
    "Предвиден отговор 5: Sasha and Malia.\n",
    "‘‘‘\n",
    "Тези предвидени отговори са ВЕРНИ, защото:\n",
    "- Съдържат пълната информация от правилния отговор.\n",
    "- Не съдържат информация, която противоречи на правилния отговор.\n",
    "- Само семантичното значение е важно; главни букви, пунктуация, граматика и редът не са важни.\n",
    "- Налучкването е позволено, при условие че правилният отговор е напълно включен и отговорът не съдържа неправилна информация или противоречия.\n",
    "- Имената може да бъдат написани както на кирилица (напр. Малия Обама), така и на латиница (напр. Malia Obama). Това не променя верността на отговора.\n",
    "Следните са примери за НЕВЕРНИ предвидени отговори.\n",
    "‘‘‘\n",
    "Въпрос: Как се казват децата на Барак Обама?\n",
    "Правилен отговор: Малия и Саша\n",
    "Предвиден отговор 1: Малия.\n",
    "Предвиден отговор 2: Малия, Саша и Сюзън.\n",
    "Предвиден отговор 3: Барак Обама няма деца.\n",
    "Предвиден отговор 4: Мисля, че е Малия и Саша. Или може би е Малия и Джаки. Или може би е Джоуи и Малия.\n",
    "Предвиден отговор 4: Въпреки че не знам техните точни имена, мога да ви кажа, че Барак Обама има три деца.\n",
    "Предвиден отговор 5: Възможно е да имате предвид Бетси и Оливия. Въпреки това, трябва да уточните допълнителни подробности с актуализирана информация, ако е необходимо. Това ли е правилният отговор?\n",
    "Предвиден отговор 6: Може би детето на Обама се казва Джеймс. Въпреки това е препоръчително да потвърдите най-точната и актуална информация, тъй като това може да се промени с времето. Този модел не винаги отразява най-актуалната информация.\n",
    "‘‘‘\n",
    "Тези предвидени отговори са НЕВЕРНИ, защото:\n",
    "-Съдържат неправилна информация или самият отговор противоречи на правилния отговор. Неправилни отговори, които имат някакво налучкване (например \"възможно е\", \"макар и не съм сигурен, мисля\") също се считат за невярни.\n",
    "Следните са примери за НЕОПИТАНИ предвидени отговори.\n",
    "‘‘‘\n",
    "Въпрос: Как се казват децата на Барак Обама?\n",
    "Правилен отговор: Малия и Саша\n",
    "Предвиден отговор 1: Не знам.\n",
    "Предвиден отговор 2: Трябва му повече контекст за кой Обама говорите.\n",
    "Предвиден отговор 3: Без да търся в интернет, не мога да отговоря на този въпрос. Въпреки това, мога да ви кажа, че Барак Обама има две деца.\n",
    "Предвиден отговор 4: Барак Обама има две деца. Знам, че едното се казва Малия, но не съм сигурен за другото.\n",
    "‘‘‘\n",
    "Тези предвидени отговори са НЕОПИТАНИ, защото:\n",
    "-Важната информация от правилния отговор не е включена в отговора.\n",
    "-Няма изявления в отговора, които противоречат на правилния отговор.\n",
    "Също така, обърни внимание на следните неща:\n",
    "-За определянето на въпроси където правилният отговор е число, предвиденият отговор трябва да бъде верен до последната значима цифра в правилния отговор.\n",
    "Например, ако въпросът е \"Колко цитати има статията за Трансформърс?\" с правилен отговор \"120 хиляди\".\n",
    "-Предвидените отговори \"120 хиляди\", \"124 хиляди\" и \"115 хиляди\" са ВЕРНИ.\n",
    "-Предвидените отговори \"100 хиляди\" и \"113 хиляди\" са НЕВЕРНИ.\n",
    "-Предвидените отговори \"около 100 хиляди\" и \"повече от 50 хиляди\" се считат за НЕОПИТАНИ, защото нито потвърждават, нито противоречат на правилния отговор.\n",
    "-Правилният отговор може да съдържа повече информация от въпроса. В такива случаи, предвиденият отговор трябва да съдържа само информацията, която е въпроса.\n",
    "-Например, ако въпросът е \"В коя серия Дерек и Мередит се омъжиха в Анатомията на Грей?\" с правилен отговор \"Сезон 7, Епизод 20: Бяла сватба\".\n",
    "И \"Сезон 7, Епизод 20\" и \"Бяла сватба\" ще се считат за ВЕРНИ.\n",
    ".\n",
    "-Не санкционирай предвидените отговори, ако пропускат информация, която може да бъде лесно извлечена от въпроса.\n",
    "-Например, ако въпросът е \"В кой град се намира OpenAI?\" и правилният отговор е \"Сан Франциско, Калифорния\". Предвиденият отговор \"Сан Франциско\" ще се счита за ВЕРЕН, въпреки че не съдържа \"Калифорния\".\n",
    "-Друг пример е въпросът \"Каква награда спечели Ръководство за предварително обучение на данни:: Измерване на датирането на база данни, покритието на домейна, качеството и токсичността на NAACL’24?\", като правилният отговор е \"Награда за най-добра статия\". Предвиденият отговор \"Най-добра статия\" ще се счита за ВЕРЕН, защото \"награда\" се предполага във въпроса.\n",
    "-За въпроса \"Каква е височината на Джейсън Уей в метри?\", правилният отговор е \"1.73 м\". Предвиденият отговор \"1.75\" ще се счита за ВЕРЕН, защото въпросът специфицира метри.\n",
    "-За въпроса \" Какво е името на съпругата на Барак Обама?\", правилният отговор е \"Мишел Обама\". Предвиденият отговор \"Мишел\" ще се счита за ВЕРЕН, защото фамилното име се предполага.\n",
    "-Не санкционирай за грешки в изписването на имената на хора, ако е ясно, че се отнася до същото име.\n",
    "-Например, ако правилният отговор е \"Хюнг Уон Чунг\", можеш да считаш следните предвидени отговори за верни: \"Хююнг Уон Чунг\", \"Хюнгуон Чунг\" или \"Хюн Уон Чунг\".\n",
    "Ето нов пример. Просто отговори с ВЕРЕН, НЕВЕРЕН, НЕОПИТАН. Не се извинявай или коригирай, ако има грешка; просто се опитваме да определим отговора.\n",
    "‘‘‘\n",
    "Въпрос: {question}\n",
    "Правилен отговор: {target}\n",
    "Предвиден отговор: {predicted_answer}\n",
    "‘‘‘\n",
    "Определи предвидения отговор на този нов въпрос като един от:\n",
    "A: ВЕРЕН\n",
    "B: НЕВЕРЕН\n",
    "C: НЕОПИТАН\n",
    "Просто върни буквите \"A\", \"B\" или \"C\", без текст около тях.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Whether the Answers are CORRECT, INCORRECT, or NOT ATTEMPTED</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialise the API key (TODO: change to use dotenv for security)\n",
    "base_url = \"https://api.aimlapi.com\"\n",
    "\n",
    "# Create an OpenAI client instance\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def get_llm_answer(question, target, predicted_answer):\n",
    "        messages = [ {\"role\": \"user\", \"content\": GRADER_TEMPLATE_EN.format(question=question, target=target, predicted_answer=predicted_answer)}]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                max_tokens=100,\n",
    "                temperature=0.0, # 0.0 is deterministic\n",
    "            )\n",
    "\n",
    "        return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bg_trivia \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/output/bg/triviaqaSimpleQA-BGMistral.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(bg_trivia\u001b[38;5;241m.\u001b[39mcolumns)  \u001b[38;5;66;03m# Print the column names to verify them\u001b[39;00m\n\u001b[1;32m      4\u001b[0m questions \u001b[38;5;241m=\u001b[39m bg_trivia[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\n"
     ]
    }
   ],
   "source": [
    "bg_trivia = pd.read_csv(\"../data/output/bg/triviaqaSimpleQA-BGMistral.csv\")\n",
    "print(bg_trivia.columns)  # Print the column names to verify them\n",
    "\n",
    "questions = bg_trivia[\"Question\"]\n",
    "gold_targets = bg_trivia[\"Answers\"]\n",
    "predicted_answers = bg_trivia[\"Predicted answers\"] \n",
    "results = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    classification = get_llm_answer(questions[i], gold_targets[i], predicted_answers[i])\n",
    "    results.append({\"Question number\": i + 1, \"Classification\": classification})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"../data/output_evaluation/bg/triviaqaSimpleQA-BGGEMMA2-llm.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
