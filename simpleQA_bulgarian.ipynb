{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleQA for the Bulgarian models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prompt for the Simple QA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grader template is taken directly form \"Measuring short-form factuality in large language models\"\n",
    "GRADER_TEMPLATE_EN = \"\"\"\n",
    "Твоята задача е да погледнеш даден въпрос, неговият правилен отговор и предвиден отговор. След това трябва да определиш дали предведения отговор е [\"ВЕРЕН\", \"НЕВЕРЕН\", \"НЕОПИТАН\"] на база на правилния отговор.\n",
    "Като за начало, ще ти дам пример за всеки един отговор [\"ВЕРЕН\", \"НЕВЕРЕН\", \"НЕОПИТАН\"], след което твоята задача ще е да определиш нов пример.\n",
    "\n",
    "Следните са примери за ВЕРНИ предвидени отговори.\n",
    "‘‘‘\n",
    "Въпрос: Как се казват децата на Барак Обама?\n",
    "Правилен отговор: Малия Обама и Саша Обама.\n",
    "Предвиден отговор 1: саша и малия обама\n",
    "Предвиден отговор 2: повечето хора биха казали Малия и Саша, но не съм сигурен и ще трябва да проверя.\n",
    "Предвиден отговор 3: Барак Обама има две дъщери. Имената им са Малия Ан и Наташа Мариан, но те се наричат обикновено Малия Обама и Саша Обама. Малия е родена на 4 юли 1998 г., а Саша е родена на 10 юни 2001 г.\n",
    "‘‘‘\n",
    "Тези предвидени отговори са ВЕРНИ, защото:\n",
    "- Съдържат пълната информация от правилния отговор.\n",
    "- Не съдържат информация, която противоречи на правилния отговор.\n",
    "- Само семантичното значение е важно; главни букви, пунктуация, граматика и редът не са важни.\n",
    "- Налучкването е позволено, при условие че правилният отговор е напълно включен и отговорът не съдържа неправилна информация или противоречия.\n",
    "Следните са примери за НЕВЕРНИ предвидени отговори.\n",
    "‘‘‘\n",
    "Въпрос: Как се казват децата на Барак Обама?\n",
    "Правилен отговор: Малия и Саша\n",
    "Предвиден отговор 1: Малия.\n",
    "Предвиден отговор 2: Малия, Саша и Сюзън.\n",
    "Предвиден отговор 3: Барак Обама няма деца.\n",
    "Предвиден отговор 4: Мисля, че е Малия и Саша. Или може би е Малия и Джаки. Или може би е Джоуи и Малия.\n",
    "Предвиден отговор 4: Въпреки че не знам техните точни имена, мога да ви кажа, че Барак Обама има три деца.\n",
    "Предвиден отговор 5: Възможно е да имате предвид Бетси и Оливия. Въпреки това, трябва да уточните допълнителни подробности с актуализирана информация, ако е необходимо. Това ли е правилният отговор?\n",
    "Предвиден отговор 6: Може би детето на Обама се казва Джеймс. Въпреки това е препоръчително да потвърдите най-точната и актуална информация, тъй като това може да се промени с времето. Този модел не винаги отразява най-актуалната информация.\n",
    "‘‘‘\n",
    "Тези предвидени отговори са НЕВЕРНИ, защото:\n",
    "-Съдържат неправилна информация или самият отговор противоречи на правилния отговор. Неправилни отговори, които имат някакво налучкване (например \"възможно е\", \"макар и не съм сигурен, мисля\") също се считат за невярни.\n",
    "Следните са примери за НЕОПИТАНИ предвидени отговори.\n",
    "‘‘‘\n",
    "Въпрос: Как се казват децата на Барак Обама?\n",
    "Правилен отговор: Малия и Саша\n",
    "Предвиден отговор 1: Не знам.\n",
    "Предвиден отговор 2: Трябва му повече контекст за кой Обама говорите.\n",
    "Предвиден отговор 3: Без да търся в интернет, не мога да отговоря на този въпрос. Въпреки това, мога да ви кажа, че Барак Обама има две деца.\n",
    "Предвиден отговор 4: Барак Обама има две деца. Знам, че едното се казва Малия, но не съм сигурен за другото.\n",
    "‘‘‘\n",
    "Тези предвидени отговори са НЕОПИТАНИ, защото:\n",
    "-Важната информация от правилния отговор не е включена в отговора.\n",
    "-Няма изявления в отговора, които противоречат на правилния отговор.\n",
    "Също така, обърни внимание на следните неща:\n",
    "-За определянето на въпроси където правилният отговор е число, предвиденият отговор трябва да бъде верен до последната значима цифра в правилния отговор.\n",
    "Например, ако въпросът е \"Колко цитати има статията за Трансформърс?\" с правилен отговор \"120 хиляди\".\n",
    "-Предвидените отговори \"120 хиляди\", \"124 хиляди\" и \"115 хиляди\" са ВЕРНИ.\n",
    "-Предвидените отговори \"100 хиляди\" и \"113 хиляди\" са НЕВЕРНИ.\n",
    "-Предвидените отговори \"около 100 хиляди\" и \"повече от 50 хиляди\" се считат за НЕОПИТАНИ, защото нито потвърждават, нито противоречат на правилния отговор.\n",
    "-Правилният отговор може да съдържа повече информация от въпроса. В такива случаи, предвиденият отговор трябва да съдържа само информацията, която е въпроса.\n",
    "-Например, ако въпросът е \"В коя серия Дерек и Мередит се омъжиха в Анатомията на Грей?\" с правилен отговор \"Сезон 7, Епизод 20: Бяла сватба\".\n",
    "И \"Сезон 7, Епизод 20\" и \"Бяла сватба\" ще се считат за ВЕРНИ.\n",
    ".\n",
    "-Не санкционирай предвидените отговори, ако пропускат информация, която може да бъде лесно извлечена от въпроса.\n",
    "-Например, ако въпросът е \"В кой град се намира OpenAI?\" и правилният отговор е \"Сан Франциско, Калифорния\". Предвиденият отговор \"Сан Франциско\" ще се счита за ВЕРЕН, въпреки че не съдържа \"Калифорния\".\n",
    "-Друг пример е въпросът \"Каква награда спечели Ръководство за предварително обучение на данни:: Измерване на датирането на база данни, покритието на домейна, качеството и токсичността на NAACL’24?\", като правилният отговор е \"Награда за най-добра статия\". Предвиденият отговор \"Най-добра статия\" ще се счита за ВЕРЕН, защото \"награда\" се предполага във въпроса.\n",
    "-За въпроса \"Каква е височината на Джейсън Уей в метри?\", правилният отговор е \"1.73 м\". Предвиденият отговор \"1.75\" ще се счита за ВЕРЕН, защото въпросът специфицира метри.\n",
    "-За въпроса \" Какво е името на съпругата на Барак Обама?\", правилният отговор е \"Мишел Обама\". Предвиденият отговор \"Мишел\" ще се счита за ВЕРЕН, защото фамилното име се предполага.\n",
    "-Не санкционирай за грешки в изписването на имената на хора, ако е ясно, че се отнася до същото име.\n",
    "-Например, ако правилният отговор е \"Хюнг Уон Чунг\", можеш да считаш следните предвидени отговори за верни: \"Хююнг Уон Чунг\", \"Хюнгуон Чунг\" или \"Хюн Уон Чунг\".\n",
    "Ето нов пример. Просто отговори с ВЕРЕН, НЕВЕРЕН, НЕОПИТАН. Не се извинявай или коригирай, ако има грешка; просто се опитваме да определим отговора.\n",
    "‘‘‘\n",
    "Въпрос: {question}\n",
    "Правилен отговор: {target}\n",
    "Предвиден отговор: {predicted_answer}\n",
    "‘‘‘\n",
    "Определи предвидения отговор на този нов въпрос като един от:\n",
    "A: ВЕРЕН\n",
    "B: НЕВЕРЕН\n",
    "C: НЕОПИТАН\n",
    "Просто върни буквите \"A\", \"B\" или \"C\", без текст около тях.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Whether the Answers are CORRECT, INCORRECT, or NOT ATTEMPTED</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialise the API key (TODO: change to use dotenv for security)\n",
    "api_key = \"\" \n",
    "base_url = \"https://api.aimlapi.com\"\n",
    "\n",
    "# Create an OpenAI client instance\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "def get_llm_answer(question, target, predicted_answer):\n",
    "    # Prepare the messages to be sent to the language model\n",
    "    messages = [{\"role\": \"user\", \"content\": GRADER_TEMPLATE_EN.format(question=question, target=target, predicted_answer=predicted_answer)}]\n",
    "\n",
    "    # Send a request to the language model to generate a completion\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\", # Specify the model to use\n",
    "        messages=messages, \n",
    "        max_tokens=100, # Limit the response to 100 tokens (we dont need more)\n",
    "        temperature=0.0, \n",
    "    )\n",
    "\n",
    "    # Return the generated response\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_trivia = pd.read_csv(\"trivia_qa_bulgarian.csv\")\n",
    "questions = bg_trivia[\"Question\"]\n",
    "gold_targets = bg_trivia[\"Answers\"]\n",
    "predicted_answers = bg_trivia[\"Predicted answers\"] \n",
    "results = []\n",
    "\n",
    "for i in range(1,len(questions)+1):\n",
    "    classification = get_llm_answer(questions[i], gold_targets[i], predicted_answers[i])\n",
    "    results.append({\"Question number\": i, \"Classification\": classification})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"SimpleQA_Bulgarian.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
